{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1839e267",
   "metadata": {},
   "source": [
    "# Daily Aggregations using Xarray\n",
    "*(author: Grant Buster)*\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Install dask-distributed: `pip install distributed --upgrade`\n",
    "- Initialize a dask client for parallel processing\n",
    "- Set dask compute chunks appropriately\n",
    "\n",
    "\n",
    "In this notebook, we demonstrate how you can use ``xarray`` to quickly and easily compute daily statistics for a year of sup3rCC data. (If it seems strange to you that we're aggregating a dataset intended to improve resolution - don't worry, we think it's a bit strange too).\n",
    "\n",
    "\n",
    "### Helpful tips\n",
    "\n",
    "- Performance is really sensitive (perhaps unsurprisingly) to the dask compute chunk size you specify. The h5 chunks on disk are way too small and result in way too many operations, adding too much overhead to performance. You can get much worse performance with xarray+dask vs. a serial read when working on a small set (~1e3) locations if your compute chunks are too small. Here, we find that `(8760, 10000)` is a good compute chunk size.\n",
    "\n",
    "- Too large of compute chunks will violate the requested Dask memory limit. If you are memory constrained, try setting a memory limit and reduce the compute chunk size.\n",
    "\n",
    "- Setting up the full aggregate dataset and then doing one `.compute()` call resulted in chaos and memory errors. The `Client` memory limit doesn't seem to do anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc2208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running on HPC node, so can use 100 processes and high memory limit\n",
    "client = Client(n_workers=100, memory_limit='100GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "year = 2015\n",
    "scenario = 'ecearth3cc_ssp245_r1i1p1f1'\n",
    "\n",
    "fp_base = '/datasets/sup3rcc/conus_{scenario}/v0.2.2_beta/sup3rcc_conus_{scenario}_{group}_{year}.h5'\n",
    "fp_pr = fp_base.replace('v0.2.2_beta', 'v0.2.2_beta/daily')\n",
    "\n",
    "kwargs = dict(engine=\"rex\", chunks={'time_index': 8784, 'gid': 100000})\n",
    "xds_trh = xr.open_mfdataset(fp_base.format(scenario=scenario, group='trh', year=year), **kwargs)\n",
    "xds_wind = xr.open_mfdataset(fp_base.format(scenario=scenario, group='wind', year=year), **kwargs)\n",
    "xds_pr = xr.open_mfdataset(fp_pr.format(scenario=scenario, group='pr', year=year), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "da = xds_trh['temperature_2m'].groupby(\"time.date\").max(\"time\").astype(np.float32).compute()\n",
    "da['date'] = pd.to_datetime(da['date'].values).astype(int)\n",
    "da = da.rename({'date': 'time'})\n",
    "\n",
    "ds_out = da.to_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "da = xds_trh['relativehumidity_2m'].groupby(\"time.date\").min(\"time\").astype(np.float32).compute()\n",
    "da['date'] = pd.to_datetime(da['date'].values).astype(int)\n",
    "da = da.rename({'date': 'time'})\n",
    "ds_out['relativehumidity_2m'] = da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3616de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "da = xds_wind['windspeed_10m'].groupby(\"time.date\").mean(\"time\").astype(np.float32).compute()\n",
    "da['date'] = pd.to_datetime(da['date'].values).astype(int)\n",
    "da = da.rename({'date': 'time'})\n",
    "ds_out['windspeed_10m'] = da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5dbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xds_pr['time'] = pd.to_datetime(xds_pr['time'].values - pd.Timedelta('12hr')).astype(int)\n",
    "ds_out['pr'] = xds_pr['pr'].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_out['temperature_2m'].attrs['aggregation'] = 'Daily maximum'\n",
    "ds_out['relativehumidity_2m'].attrs['aggregation'] = 'Daily minimum'\n",
    "ds_out['windspeed_10m'].attrs['aggregation'] = 'Daily average'\n",
    "ds_out['pr'].attrs['aggregation'] = 'Daily average'\n",
    "\n",
    "encoding = {\"temperature_2m\": {\"dtype\": \"int16\", \"scale_factor\": 0.01, '_FillValue': 100},\n",
    "            \"windspeed_10m\": {\"dtype\": \"int16\", \"scale_factor\": 0.01, '_FillValue': 120},\n",
    "            \"relativehumidity_2m\": {\"dtype\": \"uint16\", \"scale_factor\": 0.01, '_FillValue': 101},\n",
    "           }\n",
    "\n",
    "ds_out = ds_out.drop_vars('time_index', errors='ignore')\n",
    "ds_out.to_netcdf(f'sup3rcc_test_daily_{scenario}_{year}.nc', format='NETCDF4', engine=\"h5netcdf\", encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
